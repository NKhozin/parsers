{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### indianstartupnews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "\n",
    "source = 'indianstartupnews'\n",
    "\n",
    "for page in list(range(1, 30)):\n",
    "\n",
    "        base_url = f'https://indianstartupnews.com/news?page={page}'\n",
    "    \n",
    "        r = requests.get(base_url)\n",
    "    \n",
    "        soup_all = BeautifulSoup(r.text, 'lxml')\n",
    "\n",
    "        items = soup_all.find_all('div', class_=['col-sm-4 col-md-4 col-lg-4'])\n",
    "        \n",
    "        for item in items:\n",
    "            \n",
    "            try:\n",
    "                # Находим элемент ссылки (a), содержащий нужную информацию\n",
    "                link_tag = item.find('a', attrs={'aria-label': True})\n",
    "                \n",
    "                # Извлекаем URL из атрибута href\n",
    "                href = link_tag['href'] if link_tag else None\n",
    "                \n",
    "                # Извлекаем текст заголовка\n",
    "                title = link_tag.find('div', class_='post-title').get_text(strip=True) if link_tag else None\n",
    "        \n",
    "                # Находим тег <time> с классом \"date\"\n",
    "                time_tag = soup.find('time', class_='date')\n",
    "                \n",
    "                # Извлекаем текст из найденного тега\n",
    "                date = time_tag.get_text(strip=True) if time_tag else None\n",
    "        \n",
    "                url = 'https://indianstartupnews.com' + href\n",
    "        \n",
    "                r = requests.get(url)\n",
    "                \n",
    "                soup = BeautifulSoup(r.text, 'lxml')\n",
    "                \n",
    "                full_text = soup.find('div', class_=['article'])\n",
    "                \n",
    "                text = ' '.join([p.text for p in full_text.find_all('p')][:-1])\n",
    "        \n",
    "                sub_data = pd.DataFrame([[source, title, date, href, text]], columns=['source', 'title', 'date', 'href', 'text'])\n",
    "            \n",
    "                data = pd.concat([data, sub_data], axis=0)\n",
    "\n",
    "            except Exception as e:\n",
    "                    print(e)\n",
    "\n",
    "        time.sleep(1)\n",
    "            \n",
    "# Сохранение файла\n",
    "data.to_excel(f'{source}.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### businessemirates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "\n",
    "source = 'businessemirates'\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "for page in list(range(1, 40)):\n",
    "\n",
    "    base_url = f'https://businessemirates.ae/news/?page={page}'\n",
    "    \n",
    "    driver.get(base_url)\n",
    "    \n",
    "    items = driver.find_elements(By.CSS_SELECTOR, '.ib_head')\n",
    "    \n",
    "    for item in items:\n",
    "        \n",
    "        title = item.find_element(By.TAG_NAME, 'a').text\n",
    "        \n",
    "        href  = item.find_element(By.TAG_NAME, 'a').get_attribute('href')\n",
    "\n",
    "        if title!='':\n",
    "            \n",
    "            r = requests.get(href)\n",
    "            soup = BeautifulSoup(r.text, 'lxml')\n",
    "         \n",
    "            title = soup.find('div', class_=['full_news_head']).text\n",
    "            description = soup.find('div', class_=['full_news_desc']).text\n",
    "            text = soup.find('div', class_=['full_news_text']).text\n",
    "            date = soup.find('div', class_=['full_news_info']).text.split('\\n')[4]\n",
    "        \n",
    "            sub_data = pd.DataFrame([[source, title, date, href, description, text]], columns=['source', 'title', 'date', 'href', 'description', 'text'])\n",
    "    \n",
    "            data = pd.concat([data, sub_data], axis=0)\n",
    "\n",
    "# Закрыть браузер после выполнения\n",
    "driver.quit()\n",
    "\n",
    "# Сохранение файла\n",
    "data.to_excel(f'{source}.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
